# Challenges in Representation Learning, Facial Expression Recognition Challenge

მოცემულ kaggle-ის კონკურსში გვაქვს grayscale სურათები 48x48 პიქსელის რეზოლუციით და შესაბამისი ემოციების ლეიბლები. ჩვენი მიზანია, ავაწყოთ ისეთი მოდელი, რომელიც შეძლებს ახალი გამოსახულებებიდან ემოციის ამოცნობას. ამ ამოცანისთვის გამოვიყენე convolutional neural network (CNN) არქიტექტურა სხვადასხვა რეგულარიზაციის მეთოდითან ერთად, რადგან მთავარი პრობლემა იყო overfitting – მოდელი ზედმეტად ზუსტად სწავლობდა ტრეინინგ მონაცემებზე, მაგრამ ვერ ასრულებდა კარგად ვალიდაციაზე.

ამ ამოცანის გადასაჭრელად საკმაოდ ბევრი მეთოი ვცადე, როგორც ამას ფაილების რაოდენობითა და wandb-ში არსებული ლოგებითაც დაინახავდით. დასაწყისში ყველაფერი ინდივიდუალურად გავტესტე, რათა მენახა, თუ როგორ იმუშავებდნენ მოცემულ ამოცანაზე, ბოლოში კი გავაერთაინე ყველაფერი, რაც გამომადგა ერთად.

# რეპოზიტორიის სტრუქტურა
README - რასაც ამჟამად კითხულობთ. შეიცავს ინფორმაციას მოცემულ ამოცანასა და ჩემს მიერ მისი გადაჭრის მეთოდების შესახებ.

base_model.ipynb - აქ ვწვრთნი ყველაზე basic მოდელს, რომელსაც შემდეგ მოდიფიკაციებით გავაუმჯობესებ.

deep_cnn.ipynb - აქ გავზარდე მოდელის კომპლექსურობა, რათა მენახა რამდენად კარგად დაისწავლიდა მახასიათებლებს.

dropout_cnn.ipynb - აქ უკვე ვცადე dropout, რათა შემემცირებინა overfit.

globalpool_cnn.ipynb - აქ კი globalpool გამოვიყენე, რადგან როდესაც უფრო კომპლექსურ მოდელს ავაგებ მაინც არ მოხდეს overfit და ამავდროულად შემცირდეს მოდელის შინაგანი კომპლექსურობა.

hybrid_cnn.ipynb - აქ კი ზემოთ განხილული ყველა მეთოდი გავაერთიანე და ჩემი შესაძლებლობებით საუკეთესო მოდელი გავაკეთე, რომელიც არის კომპლექსური, მაგრამ overfit-ს თავს ვაცილებთ dropout-ითა და pool-ინგით.

model_inference.ipynb - აქ ვტვირთავ test-ს და ჩემს საუკეთესო მოდელს ვიყენებ submission.csv-ს დასაგენერირებლად.

# Model architecture
მე ავაწყე ჰიბრიდული CNN არქიტექტურა, რომელიც შედგება 3 ძირითადი convolutional ბლოკისგან და საბოლოო fully connected ნაწილებისგან. არქიტექტურაში თითოეულ ბლოკს მოჰყვება BatchNorm, ReLU აქტივაცია და Dropout:

  1.Conv ბლოკი: 
    გამოვიყენე Conv2d → BatchNorm2d → ReLU → MaxPool2d → Dropout

  2.Dropout:
    Convolutional ბლოკებში nn.Dropout2d(0.25) ვიყენებთ, რათა spatial სტრუქტურა უკეთ შეინარჩუნოს.
    Fully connected ნაწილებში nn.Dropout(0.5) ვიყენებთ.

# Regularization
მოცემული ამოცანის გადაჭრის დროს ხშირად ვაწყდებოდი overfitting-ს: მოდელი train-ზე აღწევდა მაღალ სიზუსტეს, მაგრამ validation-ზე – ბევრად დაბალს. ამ პრობლემის გადასაჭრელად სხვადასხვა მეთოდი ვცადე:

Dropout - გამოვიყენე Dropout. Dropout ხელს უშლის კონკრეტული ნეირონების "დაზეპირებას" და აიძულებს მოდელს, ისწავლოს განზოგადებული ფუნქციები.

Data Augmentation - ვინაიდან სურათების რაოდენობა შეზღუდულია და კლასები არაბალანსირებულია, დავამატე სურათების რენდომზე შეტრიალება მცირედით, რათა უფრო ზოგადი პატერნი დაემახსოვრებინა(არ გამოიღო პოზიტიური შედეგი :) )

Batch Normalization - ყოველი კონვოლუციური ფენის შემდეგ დავამატეთ BatchNorm, რომელიც აჩქარებს ტრენინგს და ამცირებს overfit-ის რისკს.

# Training
რეპოზიორიის სტრუქტურიდანაც ჩანს, რომ 5 სახეობის მოდელი გამოვიყენე, რომლებიცაა baseline, deep, dropout, globalpool და hybrid. მოდელის ეფექტურობის შესაფასებლად ვიყენებ crossenthropy-ს. ხოლო იმის შესაფასებლად თუ როგორ უნდა გავაუმჯობესო მოდელი ვიყენებ accuracy-ს და ამით ვხვდები ჩემს მიერ შექმნილი მოდელი overfit-შია თუ underfit-ში.

baseline - როგორც ზემოთ აღვწერე არის ყველაზე basic მოდელი უბრალოდ, რომ ამომეცნო თუ რისი გაკეთება დამჭირდებოდა მომავალში.

deep - აქ უკვე განვავრე მოდელი და დავამატე რამდენიმე შრე, რითი მისი კომპლექსურობა გავზარდე. შედეგად მოხდა overfit(აქედან გამომდინარე epoch-ების გაზრდამ არ იმოქმედა და მარტო training accuracy გაიზარდა.

dropout + globalpool - აქ უბრალოდ გავტესტე dropout და globalpool თუ რა შედეგს გამოიღებდა და გაასწორებდა თუ არა overfit-ს(გაასწორა :) )

hybrid - აქ კიდევ გავაერთიანე აქამდე მიღებული შედეგები და შევეცადე შემექმნა მოდელი, რომელიც იქნებოდა კომპლექსური cnn, მაგრამ არ გამოიწვევდა overfit-ს, რამაც ჩემი აზრით შესაფერისად იმუშავა. სწორედ ეს არის ჩემი ყველაზე კარგი შედეგის დამდები მოდელი.

# WandB Tracking
wandb ექსპერიმენტების ლინკი: https://wandb.ai/gbend22-free-university-of-tbilisi-/ml-homework-4/

***IMPORTANT***

ჩემი run-ები მაქვს გაყოფილი group-ის მიხედვით და თუ აზრის გამოტანა გინდათ მონაცემებიდან Grouping-ში group-მიუთითეთ.

***IMPORTANT***

ის შედგება 6 ნაწილისგან, რომლებშიც შესაბამისი მოდელების წვრთნის შედეგები არის შენახული. მათში ვინახავ train_loss, test_loss, train_accuracy და test_accuracy შეფასების
მეტრიკებს, ამავდროულად ვაფიქსირებ ყველა ჰიპერპარამეტრს და ვინახავ შესაბამისი მოდელის არტეფაქტს.

საუკეთესო შედეგები(hybrid-შია):

train accuracy - 0.64968

train loss - 0.94156

test accuracy - 0.60311

test loss -1.0825
